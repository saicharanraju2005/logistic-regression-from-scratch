{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of Logistic Regression (one variable) from scratch\n",
        "\n",
        "### Definitions:\n",
        "*   $x$: Independent variable\n",
        "*   $y$: Dependent variable (binary, e.g., yes/no)\n",
        "*   $\\mathbf{w}$: Weight vector including bias, $\\mathbf{w} = \\begin{bmatrix} b \\\\ w_1 \\end{bmatrix}$\n",
        "\n",
        "### Model:\n",
        "The predicted output $\\hat{y}$ is calculated using the sigmoid function:\n",
        "$$\\hat{y} = \\sigma(\\mathbf{x} \\cdot \\mathbf{w})$$\n",
        "where $\\mathbf{x} = \\begin{bmatrix} 1 \\\\ x \\end{bmatrix}$ is the augmented input vector.\n"
      ],
      "metadata": {
        "id": "Bd465zB--i8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sigmoid function:\n",
        "$$\\sigma(xw) = \\frac{1}{1 + \\exp(-xw)}$$\n",
        "\n",
        "Loss function (Binary Cross-Entropy):\n",
        "$$Loss = -\\frac{1}{m}\\sum_{i=1}^{m}[y_i \\ln(\\hat{y}_i) + (1-y_i)\\ln(1-\\hat{y}_i)]$$\n",
        "\n",
        "Gradient of the Loss Function:\n",
        "$$Gradient = -\\frac{1}{m}\\sum_{i=1}^{m}(y_i - \\hat{y}_i)x_i$$\n",
        "\n",
        "Weight Update Rule:\n",
        "$$w := w - L \\cdot Gradient$$"
      ],
      "metadata": {
        "id": "xHFWP0UB_hKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CODE:**"
      ],
      "metadata": {
        "id": "3jKDvrTfBt7D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoMofhjg-dwY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1],[2],[3],[4],[5],[6],[7]])\n",
        "y = np.array([[0],[0],[0],[1],[1],[1],[1]])\n",
        "x_ = np.insert(x,0,1,1)\n",
        "m = len(x_)\n",
        "\n",
        "w = np.array([[0.],[0.]])"
      ],
      "metadata": {
        "id": "esrUFDArB6Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1/(1+ np.exp(-z))\n",
        "\n",
        "def gradient(x_,y,w):\n",
        "    y_hat = sigmoid(x_@w)\n",
        "    return -(1/m)*(x_.T@(y-y_hat))"
      ],
      "metadata": {
        "id": "kwjw4kySB87Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 2000\n",
        "L = 0.1\n",
        "\n",
        "for j in range(epoch+1):\n",
        "    total_loss = 0\n",
        "    w -= L * gradient(x_, y, w)\n",
        "    y_hat = sigmoid(x_@w)\n",
        "    for i in range(m):\n",
        "        Loss = -(1.0 / m) * (y[i] * np.log(y_hat[i]) + (1 - y[i]) * np.log(1 - y_hat[i]))\n",
        "        total_loss += Loss\n",
        "    if j%100 == 0 or j==1000:\n",
        "        print(f\"Loss at {j} epoch : \",total_loss)"
      ],
      "metadata": {
        "id": "RnND04-ZB8nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nW:\\n\",w)\n",
        "y_hat = sigmoid(x_@w)\n",
        "print(\"\\nPredicted: \\n\",y_hat)\n",
        "\n",
        "x_new = np.array([[1,3.34]])\n",
        "y_predicted = sigmoid(x_new@w)\n",
        "print(f\"\\nPrediction for {x_new[0][1]}: {y_predicted[0][0]*100}% pass\")"
      ],
      "metadata": {
        "id": "RC6AgHQpCNtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting\n",
        "xi = np.linspace(0,6.9,100)\n",
        "xi.resize(100,1)\n",
        "xi_ = np.insert(xi,0,1,1)\n",
        "plt.scatter(x,y,marker='o',label = 'Original',color='Green')\n",
        "plt.plot(xi,sigmoid(xi_@w),color='Orange',label='Predicted sigmoid')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PrNUmFXjB8Uh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}